{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, confusion_matrix, make_scorer, classification_report\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadJSON(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def loadPCA():\n",
    "    X_train_pca = pd.read_csv(r'data/music_train_pca.csv')\n",
    "\n",
    "    y_train_pca = np.array(X_train_pca.iloc[:, -1])\n",
    "    non_music = X_train_pca[y_train_pca == 0]\n",
    "    music = X_train_pca[y_train_pca == 1][:len(X_train_pca[y_train_pca == 0])]\n",
    "    X_train_pca = music.append(non_music, ignore_index=True).sample(frac=1, random_state = 0)\n",
    "    y_train_pca = np.array(X_train_pca.iloc[:, -1])\n",
    "    X_train_pca = X_train_pca.iloc[:,:-1].values\n",
    "\n",
    "    print(\"Loaded PCA training set\")\n",
    "    \n",
    "    X_val_pca = pd.read_csv(r'data/music_validation_pca.csv').values\n",
    "    y_val_pca = X_val_pca[:,-1]\n",
    "    X_val_pca = X_val_pca[:,:-1]\n",
    "    print(\"Loaded PCA validation set\")\n",
    "    \n",
    "    X_test_pca = pd.read_csv(r'data/music_test_pca.csv').values\n",
    "    y_test_pca = X_test_pca[:,-1]\n",
    "    X_test_pca = X_test_pca[:,:-1]\n",
    "    print(\"Loaded PCA test set\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_pca)\n",
    "    X_train_scaled = scaler.transform(X_train_pca)\n",
    "    X_val_scaled = scaler.transform(X_val_pca)\n",
    "    X_test_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    return (X_train_scaled, y_train_pca, X_val_scaled, y_val_pca, X_test_scaled, y_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_score(y_true, y_pred, **kwargs):\n",
    "    rewardDict = dict()\n",
    "    #(True Value, Predicted Value)\n",
    "    rewardDict[(0,0)] = 0\n",
    "    rewardDict[(0,1)] = -3\n",
    "    rewardDict[(1,0)] = 0\n",
    "    rewardDict[(1,1)] = 1\n",
    "    \n",
    "    reward = 0\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(\"Arrays are of two different lengths!!!\")\n",
    "        return -1000000\n",
    "    for index in range(len(y_true)):\n",
    "        reward += rewardDict[(y_true[index],y_pred[index])]\n",
    "    return reward\n",
    "\n",
    "def plotROC(solution, prediction, classifierName):\n",
    "    lw = 2\n",
    "    fpr, tpr, _ = roc_curve(solution, prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for {}'.format(classifierName))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def getBestClassifier():\n",
    "    logistic_regression = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                                             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "                                             penalty='l2', random_state=None, solver='liblinear',\n",
    "                                             tol=0.0001, verbose=0, warm_start=False)\n",
    "    random_forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                                           max_depth=1000, max_features='auto', max_leaf_nodes=None,\n",
    "                                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                           min_samples_leaf=2, min_samples_split=6,\n",
    "                                           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
    "                                           oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "    nn = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "                       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "                       hidden_layer_sizes=100, learning_rate='constant',\n",
    "                       learning_rate_init=0.001, momentum=0.9,\n",
    "                       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "                       random_state=0, shuffle=True, solver='adam', tol=0.0001,\n",
    "                       validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "    voting = VotingClassifier(estimators=[('lr', logistic_regression), ('rf', random_forest), ('nn', nn)], voting=\"soft\")\n",
    "    return (voting, \"ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(y):\n",
    "    return filtering(majority_vote(y))\n",
    "\n",
    "def majority_vote(y, window = 90):\n",
    "    \"\"\"\n",
    "    Slides a window over the input and puts the label to a majority vote\n",
    "    \"\"\"\n",
    "    y_new = []\n",
    "    maxR = len(y)\n",
    "    for i in range(maxR):\n",
    "        l = i - window\n",
    "        if l < 0:\n",
    "            l = 0\n",
    "        r = i + window\n",
    "        if r > maxR - 1:\n",
    "            r = maxR - 1\n",
    "        y_new.append(np.bincount(y[l:r]).argmax())\n",
    "    return y_new\n",
    "\n",
    "def filtering(y, threshold = 50):\n",
    "    \"\"\"\n",
    "    Filters out segments of music that are shorter than 10 seconds \n",
    "    Every Frame is 200ms * 5 * 10 = 50\n",
    "    \"\"\"\n",
    "    y_string = str1 = ''.join(str(e) for e in y)\n",
    "    y_new = np.zeros(len(y))\n",
    "    musicIndexStart = 0\n",
    "    musicIndexStop = 0\n",
    "    while musicIndexStart != -1 and musicIndexStop != -1:\n",
    "        if musicIndexStop - musicIndexStart > threshold:\n",
    "            y_new[musicIndexStart:musicIndexStop] = np.ones(musicIndexStop - musicIndexStart)\n",
    "        musicIndexStart = y_string.find(\"1\",musicIndexStop)\n",
    "        musicIndexStop = y_string.find(\"0\",musicIndexStart)\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_pca, y_train_pca, X_val_pca, y_val_pca, X_test_pca, y_test_pca = loadPCA()\n",
    "classifier, name = getBestClassifier()\n",
    "\n",
    "max_val_score = np.sum(y_val_pca == 1)\n",
    "max_test_score = np.sum(y_test_pca == 1)\n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"|Training {} on PCA\".format(name))\n",
    "print(\"===============================\")\n",
    "\n",
    "classifier.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "print(\"===============================\")\n",
    "print(\"|Validation set\")\n",
    "print(\"===============================\")\n",
    "\n",
    "y_pred = post_processing(classifier.predict(X_val_pca))\n",
    "accuracy = np.around(accuracy_score(y_val_pca, y_pred) * 100, decimals = 2)\n",
    "val_profit = profit_score(y_val_pca, y_pred)\n",
    "print(\"|-Confusion Matrix: {}\".format(confusion_matrix(y_val_pca, y_pred).ravel()/len(y_pred)))\n",
    "print(\"|-Accuracy: {}\".format(accuracy))\n",
    "print(\"|-Profit: {} / {}%\".format(val_profit, np.around(val_profit* 100/max_val_score,decimals = 2)))\n",
    "print(\"L==============================\")\n",
    "plotROC(y_val_pca, y_pred, name)\n",
    "      \n",
    "    \n",
    "print(\"===============================\")\n",
    "print(\"|Test set\")\n",
    "print(\"===============================\")\n",
    "\n",
    "y_pred_test = post_processing(classifier.predict(X_test_pca))\n",
    "accuracy = np.around(accuracy_score(y_test_pca, y_pred_test) * 100, decimals = 2)\n",
    "test_profit = profit_score(y_test_pca, y_pred_test)\n",
    "print(\"|-Confusion Matrix: {}\".format(confusion_matrix(y_test_pca, y_pred_test).ravel()/len(y_pred_test)))\n",
    "print(\"|-Accuracy: {}\".format(accuracy))\n",
    "print(\"|-Profit: {} / {}%\".format(test_profit, np.around(test_profit* 100/max_test_score,decimals = 2)))\n",
    "print(\"L==============================\")\n",
    "plotROC(y_test_pca, y_pred_test, name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
